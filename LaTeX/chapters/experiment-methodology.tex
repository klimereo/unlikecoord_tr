\section{Overview of the chapter}

The empirical backbone of the thesis is built upon the acceptability judgment task. The experimental setup not only enables the validation of the examples found in the corpus but also makes it possible for testing structures that were absent in the corpus. 

Details about the specific methodology employed for the acceptability judgment task are elucidated in \S \ref{sec:methodologyexp}. Subsequently, \S \ref{sec:resultsexp} presents and discusses the findings obtained from the experiment. Finally, \S \ref{sec:conclusionexp} provides a summary of the results within the context of the hypothesis proposed in the thesis.

\section{Methodology} \label{sec:methodologyexp}
\subsection{Experimental design} \label{sec:experimentaldesign}
The acceptability judgment task implemented in the thesis followed a specific form of repeated measures factorial design. The hypothesis was broken down into two conceptual blocks to facilitate the factorial design: 1) the category block where the coordination of unlike categories is investigated; 2) the case block where the coordination of unlike cases is investigated. The category block followed a 2$\times$2 factorial design where the interactions between the independent variables of syntactic category and syntactic function are modeled. While the 2$\times$2 factorial design was pursued in the case block as well, this could not be achieved due to the nature of Turkish case and function mapping. As a result, the case block was conceived as a single factor with three levels (distinct sentence types), which will be discussed later. The measured (dependent) variable was the judgment of native speakers and it was a quantitative one as the participants expressed their judgments on a 7-point Likert scale (from --3 to $+$3). 

The category block encompassed four sentence types (as per the factorial design) in total, which are illustrated in Table \ref{CATBlock-Table} along with their respective codes.
In the table, the sentence type encoded as LCAT-LF denotes a coordination where conjuncts match both in their syntactic category and function. The conjuncts found in sentence type UCAT-UF, however, neither match in their syntactic category nor their syntactic function. Within the context of the hypothesis tested in the experiment, the sentence types listed under the ``Like Functions'' column (LCAT-LF and UCAT-LF) should have similar scores and collectively receive significantly higher scores than the ones under the column ``Unlike Functions''. This stems from the fact that it is the discrepant functions that are hypothesized to cause unacceptability rather than the individual categories of conjuncts.

\begin{table}[!h]
	\centering
	\scalebox{0.92}{
		\begin{tabular}{ccc}
			\textbf{}                  & \textbf{Like Functions} & \textbf{Unlike Functions} \\ \hline \hline
			\textbf{Like Categories}   & LCAT-LF                 & LCAT-UF                   \\
			\textbf{Unlike Categories} & UCAT-LF                 & UCAT-UF \\
			\hline \hline                 
	\end{tabular} }
	\caption{The category block}
	\label{CATBlock-Table}
\end{table}


The same factorial design was also pursued but could not be enforced in the case block, as can be seen in Table \ref{CASEBlock-Table}. LCASE-UF type of coordination, where conjuncts match in their cases but not in their functions, seems to be impossible in Turkish as each Turkish case is commonly associated with a particular grammatical function. 

\begin{table}[!h]
	\centering
	\scalebox{0.92}{
		\begin{tabular}{ccc}
			\textbf{}             & \textbf{Like Functions} & \textbf{Unlike Functions} \\ \hline \hline
			\textbf{Like Cases}   & LCASE-LF                & \st{LCASE-UF}                  \\
			\textbf{Unlike Cases} & UCASE-LF                & UCASE-UF \\
			\hline \hline                
	\end{tabular} }
	\caption{The case block}
	\label{CASEBlock-Table}
\end{table}

The nominative case, however, is a significant exception to this strict association between cases and functions in Turkish. As discussed earlier, in addition to its typical mapping to the subject function, the nominative is also used to mark non-specific objects in Turkish. Nevertheless, coordination of a nominative object with a nominative subject can only be postulated on a theoretical level as this coordination results either in both being interpreted as non-specific objects (see (\ref{exDOM})) or subjects if one can ignore the missing obligatory object of the verb \textit{gör} `see'.

\pex[glspace=!.7em,everygla={},everyglb={},aboveglbskip=-.15ex, interpartskip=15pt]
\label{exDOM} \begingl
\gla Kedi ve köpek gör-dü. //
\glb cat.\textsc{nom} and dog.\textsc{nom} see-\textsc{pst}-\textsc{3p} //
\glft `Intended meaning: The cat saw some dog.' // `Available meanings: (He/she/it) saw some cat and some dog.\\
\endgl
\xe

For that reason, the case block contains only three sentence types that are conceptually identical to the ones observed in the category block. In the case block, however, the category variable is replaced with the case variable, as this block models the interactions between the cases and functions of conjuncts. Likewise, for the hypothesis to be supported, the sentence types listed under the ``Like Functions'' should receive significantly higher scores by native speakers compared to the sentence type UCASE-UF.

\subsection{Materials}

The material preparation was heavily based on the token-set methodology proposed by Wayne Cowart (\citeyear{cowart1997}) in his seminal work, \textit{Experimental Syntax}. According to this methodology, the experiment material should be devised as a collection of distinct token sets that consist of different sentence types formulated within the context of the factorial design testing the hypothesis. Crucially, the sentences in a given token set must be as similar to each other as practically possible. This acts as a control mechanism minimizing extraneous effects that may arise from lexical differences between the tokens. An example of a token set can be seen in (\ref{cattokenset}), which contains 4 sentences, each representing one of the 4 different sentence types discussed previously within the context of the category block. Token sets devised for the case block, on the other hand, are slightly different due to the different number of sentence types available in this block (see (\ref{casetokenset})). As can be observed, the sentences that belong to the same token set are as similar to each other as possible to control for lexical processing effects.

\pex[glspace=!1em,everygla={},everyglb={},aboveglbskip=-.15ex, interpartskip=15pt]
\label{cattokenset}
\a
\begingl
\gla {[} Saat-im-i{]}\textsubscript{NP\textit{object}} ve {[} telefon-um-u{]}\textsubscript{NP\textit{object}} nazikçe çekmece-m-e koy-du-m. //
\glb {}watch-\textsc{1sg.poss}-\textsc{acc}{} and {phone}-\textsc{1sg.poss}-\textsc{acc}{} gently drawer-\textsc{1sg.poss}-\textsc{dat} put-\textsc{pst}-\textsc{1sg} //
\glft `I gently put my watch and my cellphone in my drawer.' \trailingcitation{\textbf{LCAT-LF}} //
\endgl
\a
\begingl\gla Saat-im-i {[} nazik-çe{]}\textsubscript{AdvP\textit{adjunct}} ve {[} dikkat-le{]}\textsubscript{NP\textit{adjunct}}  çekmece-m-e koy-du-m. //
\glb watch-\textsc{1sg.poss}-\textsc{acc} gentle-\textsc{advz} and care-\textsc{ins} drawer-\textsc{1sg.poss}-\textsc{dat} put-\textsc{pst}-\textsc{1sg} //
\glft `I put my watch in my drawer gently and with care.' \trailingcitation{\textbf{UCAT-LF}} //
\endgl
\a
\begingl
\gla {[} Saat-im-i{]}\textsubscript{NP\textit{object}} ve {[} çekmece-m-e{]}\textsubscript{NP\textit{oblique}} nazikçe koy-du-m. //
\glb {}watch-\textsc{1sg.poss}-\textsc{acc}{} and {}drawer-\textsc{1sg.poss}-\textsc{dat}{} gently put-\textsc{pst}-\textsc{1sg} //
\glft `I gently put my watch and in my drawer.' \trailingcitation{\textbf{LCAT-UF}} //
\endgl
\a
\begingl
\gla {[} Saat-im-i{]}\textsubscript{NP\textit{object}} ve {[} nazik-çe{]}\textsubscript{AdvP\textit{adjunct}} çekmece-m-e koy-du-m. //
\glb {}watch-\textsc{1sg.poss}-\textsc{acc}{} and {}gentle-\textsc{advz}{} drawer-\textsc{1sg.poss}-\textsc{dat}  put-\textsc{pst}-\textsc{1sg} //
\glft `I put my watch and gently in my drawer.' \trailingcitation{\textbf{UCAT-UF}} //
\endgl
\xe


\pex[glspace=!1em,everygla={},everyglb={},aboveglbskip=-.15ex, interpartskip=15pt]
\label{casetokenset}
\a
\begingl
\gla Oğlum-a internet-ten {[} şapka{]}\textsubscript{NOM\textit{object}} ve {[} ayakkabı{]}\textsubscript{NOM\textit{object}} al-dı-m. //
\glb son-\textsc{dat} internet-\textsc{abl} hat and shoe buy-\textsc{pst}-\textsc{1sg} //
\glft `I bought my son a pair of shoes and a hat through the internet.' \trailingcitation{\textbf{LCASE-LF}} //
\endgl
\a
\begingl
\gla Oğlum-a {[} internet-ten{]}\textsubscript{ABL\textit{adjunct}} ve {[} kredi kartı-yla{]}\textsubscript{INS\textit{adjunct}} ayakkabı al-dı-m. //
\glb son-\textsc{dat} internet-\textsc{abl} and credit card-\textsc{ins} shoe buy-\textsc{pst}-\textsc{1sg} //
\glft `I bought my son a pair of shoes through the internet and by credit card.' \trailingcitation{\textbf{UCASE-LF}} //
\endgl
\a
\begingl
\gla {[} Oğlum-a{]}\textsubscript{DAT\textit{oblique}} ve {[} iste-diğ-i + ayakkabı-yı{]}\textsubscript{ACC\textit{object}} internetten al-dı-m. //
\glb {}son-\textsc{dat}{} and {}want-\textsc{ptcp}-\textsc{3sg.poss} shoe-\textsc{acc}{} internet-\textsc{abl} buy-\textsc{pst}-\textsc{1sg} //
\glft `I bought my son and the pair of shoes he wanted through the internet.' \trailingcitation{\textbf{UCASE-UF}} //
\endgl
\xe

\begin{sloppypar}
However, the material for the judgment task must not be limited to only one token set. Ultimately, the rationale behind constructing token sets is to test the participant's `reaction' to the sentence stimuli across different sentences in a controlled and standardized manner. Therefore, for each block, 12 distinct token sets were constructed, which amounted to 24 token sets and 84 sentences in total. 
\end{sloppypar}


The research designs based on repeated measures are highly susceptible to sequence effects and often need carefully designed counterbalancing schemes \citep[pp.\ 305--306]{grazianoandrauli}. In the present study, the counterbalancing scheme involved the use of (an equal number of) filler sentences interspersed (randomized) with the sentence stimuli. Their function was to eliminate priming effects as well as to gauge the participant's understanding of the task and attention throughout the task. To control for learning effects, all the fillers contained coordination as well, but they were not constructed based on any particular sentence type, incorporating different types of coordination. Moreover, the fillers represented the extremities of acceptable/unacceptable dichotomy. While half of them were outright unacceptable (to the point of being incomprehensible), the other half were perfectly acceptable. Additionally, some of the fully grammatical filler sentences incorporated semantic oddities and region-specific uses, which were used to evaluate the participant's sensitivity to semantic content and regional variance. In conclusion, the typical issues inherent in the research design were tackled on the level of individual participant's individual responses to filler sentences.

In addition to stimuli and filler sentences, a set of eight demographic questions was developed. These questions aimed to gather information about the participants' demographics, including their sex, age, native language, potential bilingualism, the region where their native language(s) were acquired, education level, and educational background/major. The inclusion of these questions served two purposes: obtaining essential demographic information and controlling for potential confounding variables, such as bilingualism and education level.

\subsection{Survey structure and presentation}

\begin{sloppypar}
The way the material is presented to the participant is equally important in the implementation of token-set methodology. First, the participant must judge exactly one sentence type from a given token set. Therefore, multiple sentence types from the same token set cannot be presented to a single participant. Second, it must be ensured that the participant judges all the sentence types tested in the study. Namely, the participant must encounter all the sentence types demonstrated in Tables \ref{CATBlock-Table} and \ref{CASEBlock-Table} throughout the survey. Last but not least, the participant must judge the same number of sentence tokens for each type. The last requirement imposes a ``democratic'' representation scheme where each sentence type must be represented by an equal number of representatives in the survey. For example, if the LCAT-LF type is represented by 4 distinct sentence tokens, the other types must be represented by 4 representatives as well. 
\end{sloppypar}

\begin{sloppypar}
To conform to these requirements, 4 different surveys (sub-experiments) were constructed following a Latin square procedure.\footnote{2-survey configuration was also considered, since it is also compatible with the specific design and requirements of the token-set methodology. 2-survey design, however, was deemed to be too exhausting for the participant due to the sheer number of sentences in the material pool. Furthermore, the schematic representation of how the collection of token sets from the material pool is equally distributed among the 4 surveys in a Latin square procedure can be seen in the Appendix \ref{app:subsurveys}.} Each survey contained distinct 21 sentence stimuli. While 12 of them were sentences taken from the collection of category block token sets, 9 were from the collection of the case block. To comply with the democratic representation scheme, each sentence type (from both blocks) is represented by 3 distinct sentences extracted from distinct token sets.\footnote{The category block tested 4 different sentence types. 12/4 gives us 3 representatives for each type. In contrast, the case block tested 3 sentence types, which gives us 3 representatives for each type again due to 9/3.}
\end{sloppypar}

The survey was presented such that each sentence stimulus was followed by a filler sentence. This ensured that no sentence stimulus was followed by another sentence stimulus. While this order of presentation was fixed beforehand, exactly which sentence stimulus or filler appears in an appropriate slot was randomly chosen from the pool of 21 sentence stimuli and the pool of 22 filler sentences, respectively. Apart from fillers and sentence stimuli, 3 practice sentences were also included at the beginning of the survey for the participant to acclimatize to the survey platform. In conclusion, each survey presented 46 distinct sentences to be judged, including the practice sentences.


The described survey design was implemented on LimeSurvey Community Edition (\textit{ver.} 3.28) hosted by kognilab\footnote{Kognilab is an experimental philosophy lab run by researchers from University of Warsaw. For more information, the following link can be visited: \texttt{www.kognilab.pl}} and constructed surveys were distributed through the same platform. The distribution process ensured that each participant was assigned to only one survey and all surveys were assigned the same number of participants. All surveys commenced with the presentation of demographic questions. 

In the immediately following section, the instructions supplemented by example evaluations were shown.\footnote{See Appendix \ref{app:instruct} for the translated version of the instructions.} The chief aim of the instructions was to explain that the task was neither about applying the (typically prescriptive) grammar/orthography rules learned at school nor about evaluating the propositions expressed in the sentences. To this end, instructions prompted participants to imagine a situation in their daily lives where they encounter the presented sentence. Through this embodied context, the meaning of the 7-point Likert scale (from --3 to $+$3) was explained. The highest score, 3, was to be used for natural-sounding sentences that are likely to be constructed by a native speaker of Turkish. The lowest score, --3, however, was to be used for highly-problematic (borderline incomprehensible) sentences that can only be formulated by a foreigner who just started learning Turkish. To illustrate that the task was not about evaluating the proposition expressed by the sentence, a fully grammatical sentence expressing a controversial political opinion was used as an example. Here the instructions explicitly informed that such a sentence should always receive the highest score despite its semantic content may not truthfully reflect the actual states of affairs or be conflicting with the participant's world-view. 

Right after the instructions section, the sentences were presented (starting with the 3 practice sentences) to the participant one by one. Although the participant was allowed to save their partial answers and later return to the survey for completion, they were not allowed to go back and change their scores.


\subsection{Participants}

During the recruitment process, the convenience sampling method was used and the voluntary nature of the participation was emphasized throughout the advertisement process. Bursa Uluda\u{g} University, which is one of the biggest universities in Turkey, constituted the primary source of recruitment because of the author's personal connections with the faculty staff. The other sources of recruitment were friends, relatives and their acquaintances. 

83 participants attempted the online survey, and 67 of them completed it. The participants who gave partial answers were automatically eliminated from the study. Of the remaining 67 participants, 19 more participants were eliminated. Of those 19, two were eliminated as they were not native speakers of Turkish and 17 were determined to have provided invalid answers on the basis of the scores that they gave to filler sentences (the details of this elimination procedure is explained the following selection). As a result, the answers of 48 participants were considered as valid and were subject to the statistical tests.

The sample consisted of relatively well-educated participants as 32 were undergraduate students/graduates and 12 were post-graduate students/graduates. Consequently, this led to a relatively young sample where the mean age was 30.25 years (\textit{SD} = 11.22). The majority of the participants were female. Out of 48 participants, 31 were females, compared to 15 males and 2 participants who marked the `other' option. The demographic information regarding bilingualism showed that most of the participants seem to have acquired Turkish in a strictly monolingual environment (n=40). Even though the recruitment process took place only in one city (Bursa) in the Marmara region of Turkey, 18 out 48 participants reported to have acquired Turkish in other regions of Turkey, which contributed to the representativeness rate of the sample. The global rise in the number of bilinguals (at least in the educated population) was observed in the present study as well. 34 participants reported that they speak (mostly at an intermediate level) either one or two foreign languages. When it comes to the academic majors of the participants, social sciences was the most common academic major observed among the participants (n=31), which was followed by fine arts with 9 participants. The least common academic majors were physical sciences and humanities as each was represented by only 2 participants.

\subsection{Participant elimination}

Before conducting statistical tests, it is crucial to detect and eliminate participants who did not fill out the surveys correctly. In the case of acceptability judgment tasks, this procedure is mainly done on the basis of the scores that a participant gives to grammatical/ungrammatical filler sentences. 

One straightforward procedure is to assume arbitrary threshold values for grammaticality and ungrammaticality and eliminate participants whose mean scores of grammatical/ungrammatical fillers violate these thresholds. However, this method has limitations, as the chosen threshold values lack statistical justification and different participants tend to interpret the rating scale differently. Alternatively, outliers can be detected based on basic statistical methods of outlier detection, such as \textit{z}-score and Interquartile Range (IQR). However, blindly relying on these methods can be problematic within the context of acceptability judgment tasks as such methods tend to disregard the unique distribution of data points and overlook the conceptual significance of scale points.

To illustrate, consider the commonly employed IQR outlier detection method. First, the dataset is sorted in ascending order. Then, the first quartile ($Q1$) and the third quartile ($Q3$) are calculated by finding the medians of the lower and upper halves of the dataset, respectively. The IQR is then obtained by subtracting $Q1$ from $Q3$. Subsequently, a threshold multiplier is defined to determine the range for outliers, which is typically assumed to be 1.5 or 3. The lower threshold (LT) and upper threshold (UT) are obtained by subtracting and adding the threshold multiplier multiplied by the IQR to $Q1$ and $Q3$, respectively. Finally, outliers are identified as any data points falling below the lower bound or above the upper bound. The steps of the IQR outlier detection method for a given distribution are outlined below:

\pex
\vspace{-1.4em}
\begin{equation*}
	\renewcommand\arraystretch{1.5}
	\begin{array}{@{}ll}
		Q1 & = \text{Mdn}(\text{lower half of dataset}) \\
		Q3 & = \text{Mdn}(\text{upper half of dataset}) \\
		\text{IQR} & = Q3 - Q1 \\
		\text{LT}  & = Q3 - (\text{threshold multiplier} \times \text{IQR}) \\
		\text{UT} & = Q1 + (\text{threshold multiplier} \times \text{IQR}) \\
	\end{array}
\end{equation*}
\xe

In the given equations, several variables are defined: $Q1$ represents the first quartile, $Q3$ represents the third quartile, IQR represents the interquartile range, LT represents the lower threshold, UT represents the upper threshold, and the threshold multiplier is the value chosen to determine the range for outliers.

By adjusting the threshold multiplier, the stringency of the outlier detection procedure can be controlled. A higher threshold multiplier results in a more lenient detection approach, while a lower threshold multiplier leads to a more conservative approach. For instance, a threshold multiplier of 1.5 is relatively conservative, as it classifies more data points as outliers. Conversely, selecting a threshold multiplier of 3 allows for a broader range of values to be considered normal, resulting in a more lenient detection approach, where fewer data points may be identified as outliers.


In the context of this study, implementing the IQR method with a threshold multiplier of 3 yields an upper threshold of 1.63 for ungrammatical fillers and a lower threshold of -0.27 for grammatical fillers. In other words, this implementation suggests keeping participants that scored, on average, fully grammatical sentences above --0.27 and participants who gave positive scores on average (i.e., 1.63) to outright ungrammatical sentences. Hence, it is clear that the threshold multiplier of 3 fails to capture the meaning of scale points. The commonly used threshold multiplier of 1.5 results in more meaningful threshold values, with an upper threshold of -0.40 for ungrammatical fillers and a lower threshold of 1.09 for grammatical fillers. Nonetheless, this standard approach proved overly conservative and led to the exclusion of 20 participants.

\begin{sloppypar}
As a result, for this study, the threshold multiplier was adjusted to 1.6 to achieve a more balanced outlier detection procedure. This modification aimed to align with the meaning of the scale points while maintaining a reasonable balance between strictness and leniency in identifying outliers. This adjustment led to the exclusion of participants with mean ungrammatical filler scores exceeding $-$0.27 or mean grammatical filler scores falling below 1. Breaching either threshold resulted in participant elimination. 
\end{sloppypar}

\pex
\vspace{-1.4em}
\begin{equation*}
	\renewcommand\arraystretch{1.5}
	\begin{array}{@{}ll}
		\text{LT}_{\text{gram\_fillers}}  & = Q3_{\text{gram\_fillers}} - (1.6 \times \text{IQR}_{\text{gram\_fillers}}) \\
		\text{UT}_{\text{ungram\_fillers}} & = Q1_{\text{ungram\_fillers}} + (1.6 \times \text{IQR}_{\text{ungram\_fillers}}) \\
	\end{array}
\end{equation*}
\xe


\subsection{Statistical tests}

The numerical judgment data collected via Likert scale violates some of the mathematical assumptions of parametric statistical tests. Crucially, parametric tests assume that the responses are normally distributed and are on a scale that qualifies as interval. However, the judgment data obtained via Likert scale rarely satisfies the first assumption\footnote{The data obtained within the context of the present study also violates the normality assumptions as validated by Q-Q plots and Shapiro-Wilk tests conducted.} and never fulfills the second assumption as Likert scale is ordinal.
 
\begin{sloppypar}
Nevertheless, parametric tests have proven themselves to be fairly resistant to these violations \citep{Norman2010} and produce results congruent with their \mbox{non-parametric} counterparts \citep{sprouse_schutze_judgmentdata}. For this reason, \textit{linear mixed-effects models},\footnote{The utilization of linear-mixed effects models is well-justified in experimental syntax, as well as in other experimental approaches to linguistic investigation \citep{gibsonetal_2011, cunnings_2012}.} which is a parametric linear model allowing to account for random effects, constituted the primary statistical tool for hypothesis testing in the present study. In the model, participant and sentence ID are encoded as random effects while the case/category and grammatical function as fixed effects. Additionally, Wilcoxon signed-rank test \citep{wilcoxon}, which is the non-parametric alternative of dependent samples \textit{t}-test, was employed in various comparison configurations involving two conditions.
\end{sloppypar}

\begin{sloppypar}
While the data exploration, preparation and preprocessing were done in Python (\textit{version} 3.8.12) with the help of \textit{pandas} \citep{mckinney-pandas}, \textit{numpy} \citep{harris2020array} and \textit{scipy} \citep{scipy} libraries, statistical analyses and plotting were achieved in R (\textit{version} 4.2.3) with \textit{lme4} \citep{lme4} and \textit{ggplot2} \citep{ggplot2} packages, respectively.
\end{sloppypar}




